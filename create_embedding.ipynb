{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents to vectors using a text embedding model\n",
    "\n",
    "In this notebook we show how we use text embedding models to take articles in the format of raw text and turn them into vectors. The vectors are meant to capture the \"semantic meaning\" of the text, meaning that articles with similar content and writing style will be close to teach other. For this specific notebook we use articles published in the Physics Education Research Conference Proceedings (PERC Proceedings), in the years 2001 to 2023. The text has already been scraped using the library PyMuPDF (which can handle text extration from PDFs with multiple columns) and is in a DataFrame together with some metadata such as author, title, and year of publication etc. This dataframe has been stored as a pickle file (extension .pkl), and cleaned in such a way that it is ready to be used in a text embedding model.\n",
    "\n",
    "To embed the articles we use the API from hugging face transformers library. The library has a large number of pre-trained models, and we use a model from jinaai called jina-embeddings-v2-small-en. This was chosen because it is a small model, with a long context window (roughly 8k tokens). This is important because the articles are quite long. Although there are better models out there many of them have smaller context windows, are much larger or perform worse.\n",
    "\n",
    "To access this model, you will need to go through a few initial steps:\n",
    "1. Make an account on HuggingFace (https://huggingface.co/), and generate an access token (https://huggingface.co/docs/hub/en/security-tokens)\n",
    "2. In your command line, run `huggingface-cli login` and enter your access token\n",
    "3. Open your jupyter notebook and run the code below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "First, we import our libraries: transformers to access the embeddings LLM, pickle to store the dataframe, and numpy for some data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "from transformers import AutoModel\n",
    "import pickle as pkl \n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import our embeddings model. Remember, if you haven't made an account with HuggingFace and authenticated yourself with an access token, this won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v2-small-en\", trust_remote_code=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our text data\n",
    "\n",
    "Using pickle to load the dataset. We find the cleaned/processed text in the column \"text\". The other columns have metadata for the texts we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>PDF Link</th>\n",
       "      <th>doi</th>\n",
       "      <th>year</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inductive Influence of Related Quantitative an...</td>\n",
       "      <td>Philip Dukes and David E. Pritchard</td>\n",
       "      <td>https://www.per-central.org/../items/perc/990.pdf</td>\n",
       "      <td>10.1119/perc.2001.inv.001</td>\n",
       "      <td>2001</td>\n",
       "      <td>(Invited paper for proceedings of Physics Educ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An Investigation on the Impact of Implementing...</td>\n",
       "      <td>Lawrence T. Escalada</td>\n",
       "      <td>https://www.per-central.org/../items/perc/1023...</td>\n",
       "      <td>10.1119/perc.2001.inv.002</td>\n",
       "      <td>2001</td>\n",
       "      <td>An Investigation on the Impact of Implementing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Context in the Context of Physics and Learning</td>\n",
       "      <td>Noah D. Finkelstein</td>\n",
       "      <td>https://www.per-central.org/../items/perc/1025...</td>\n",
       "      <td>10.1119/perc.2001.inv.003</td>\n",
       "      <td>2001</td>\n",
       "      <td>Context in the Context of Physics and Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Observing Students' Use of Computer-based Tool...</td>\n",
       "      <td>Elizabeth George, Maan Jiang Broadstock, and J...</td>\n",
       "      <td>https://www.per-central.org/../items/perc/1027...</td>\n",
       "      <td>10.1119/perc.2001.inv.004</td>\n",
       "      <td>2001</td>\n",
       "      <td>important for learning.9 With VBL, \\ngraphs ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Problem Solving and Conceptual Understanding</td>\n",
       "      <td>William J. Gerace</td>\n",
       "      <td>https://www.per-central.org/../items/perc/1028...</td>\n",
       "      <td>10.1119/perc.2001.inv.005</td>\n",
       "      <td>2001</td>\n",
       "      <td>Problem Solving and Conceptual Understanding \\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Inductive Influence of Related Quantitative an...   \n",
       "1  An Investigation on the Impact of Implementing...   \n",
       "2     Context in the Context of Physics and Learning   \n",
       "3  Observing Students' Use of Computer-based Tool...   \n",
       "4       Problem Solving and Conceptual Understanding   \n",
       "\n",
       "                                             authors  \\\n",
       "0                Philip Dukes and David E. Pritchard   \n",
       "1                               Lawrence T. Escalada   \n",
       "2                                Noah D. Finkelstein   \n",
       "3  Elizabeth George, Maan Jiang Broadstock, and J...   \n",
       "4                                  William J. Gerace   \n",
       "\n",
       "                                            PDF Link  \\\n",
       "0  https://www.per-central.org/../items/perc/990.pdf   \n",
       "1  https://www.per-central.org/../items/perc/1023...   \n",
       "2  https://www.per-central.org/../items/perc/1025...   \n",
       "3  https://www.per-central.org/../items/perc/1027...   \n",
       "4  https://www.per-central.org/../items/perc/1028...   \n",
       "\n",
       "                         doi  year  \\\n",
       "0  10.1119/perc.2001.inv.001  2001   \n",
       "1  10.1119/perc.2001.inv.002  2001   \n",
       "2  10.1119/perc.2001.inv.003  2001   \n",
       "3  10.1119/perc.2001.inv.004  2001   \n",
       "4  10.1119/perc.2001.inv.005  2001   \n",
       "\n",
       "                                                 raw  \n",
       "0  (Invited paper for proceedings of Physics Educ...  \n",
       "1  An Investigation on the Impact of Implementing...  \n",
       "2  Context in the Context of Physics and Learning...  \n",
       "3  important for learning.9 With VBL, \\ngraphs ar...  \n",
       "4  Problem Solving and Conceptual Understanding \\...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/PERC2001-2023_ExtraArticles/processed_text.pkl\", \"rb\") as f:\n",
    "    df = pkl.load(f)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating embeddings\n",
    "\n",
    "Next, we iterate over the rows of our dataframe, and create the embeddings from the raw text. This takes a little while (approximately 2 hours 20 min minutes on a 2023-era M2 Macbook Pro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def encode_text(row):\n",
    "    text = row['raw']\n",
    "    embedding = model.encode(text)\n",
    "    return embedding.tolist()\n",
    "\n",
    "# Apply the function along the rows and assign the result to the new 'embedding' column\n",
    "df['embedding'] = df.apply(encode_text, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving our dataframe\n",
    "\n",
    "Finally, we store the updated DataFrame with the embeddings in a pickle file. This will be used later when we analyze the texts by their embeddings and marks the end for the notebook, thanks for following along :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/PERC2001-2023_ExatraArticles/embeddings_jina.pkl\", \"wb\") as f:\n",
    "    pkl.dump(df, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4 (v3.11.4:d2340ef257, Jun  6 2023, 19:15:51) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
